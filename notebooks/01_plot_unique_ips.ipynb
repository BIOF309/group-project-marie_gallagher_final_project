{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickly Detecting Anomalies in Web site traffic\n",
    "\n",
    "---\n",
    "\n",
    "***Final Project, FAES BIOF 309 Introduction to Python, Fall 2018***\n",
    "\n",
    "**Marie Gallagher, mgallagher@mail.nih.gov**\n",
    "\n",
    "## Overview\n",
    "\n",
    "The purpose of this project is to provide a faster way to visualize\n",
    "data than (repeatedly) importing data into Excel and creating a \n",
    "chart.  This will save me time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "One of my work tasks is to provide statistics about Web site use.\n",
    "Over the years, my institute has mandated various Web analytics software\n",
    "including: awstats, WebTrends and Google Analytics.\n",
    "\n",
    "Each piece of software analyzes and displays results differently.\n",
    "So switching to different Web analytics software usually creates the \n",
    "appearance of a massive increase or decrease in traffic.\n",
    "\n",
    "I need a way to tell whether there has been a legitimate unexpected\n",
    "change in Web site traffic.  Unique IP addresses per day turns out \n",
    "to be a reasonably reliable indicator.\n",
    "\n",
    "Anomalies can also happen if the Web site is the subject of a denail\n",
    "of service attack or if an event of national or international interest \n",
    "is related to content on the Web site.  Having a way to quickly visualize \n",
    "the number of unique IP addresses daily over time will help me quickly \n",
    "spot anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "My data for this project contains the number of unique IP addresses \n",
    "accessing a Web site each day.  A few lines of data follows:\n",
    "```\n",
    "06/01/2018|5565|515120|515120|515120\n",
    "06/02/2018|4801|518657|518657|518657\n",
    "06/03/2018|4069|451881|451881|451881\n",
    "06/04/2018|4859|493762|493762|493762\n",
    "06/05/2018|4816|514587|514587|514587\n",
    "```\n",
    "\n",
    "- We are interested in the first two columns.  We want to ignore the rest of the columns.\n",
    "\n",
    "- The first column contains dates, but they are in the form MM/DD/YYYY rather than YYYY-MM-DD.\n",
    "\n",
    "- There are no column headers in this data.\n",
    "\n",
    "- The columns are separated by the \"pipe\" character rather than commas, spaces or tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# OR\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the version of the numpy package, just to satifsy my curiosity\n",
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to Martin for requirements.txt that imports pandas into Binder!\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of error in Binder, check requirements.txt for missing matplotlib line.\n",
    "import matplotlib.pyplot as plt\n",
    "# May not need either of the following.  Experiment and test...\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the location of the data files.\n",
    "# \"../data/raw/\" does not work with Google Colaboratory and Binder.  Why???  ARGH!!!\n",
    "# Plan B: Pull data from a url like \"https://github.com/BIOF309/group-project-marie_gallagher_final_project/tree/master/notebooks/data/raw/filename.txt\"\n",
    "url_path = 'https://raw.githubusercontent.com/BIOF309/group-project-marie_gallagher_final_project/master/notebooks/data/raw/'\n",
    "url_path = 'https://raw.githubusercontent.com/MarieGallagher/group-project-marie_gallagher_final_project/master/notebooks/data/raw/'\n",
    "data_dir = \"./data/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for not being able to read files if using Colaboratory or Binder.  \n",
    "# use_data_from = \"data_dir\" when working locally.\n",
    "# use_data_from = \"url_path\" when NOT working locally.\n",
    "use_data_from = \"url_path\"\n",
    "# Check for a typo in the value of use_data_from.\n",
    "if (use_data_from != \"url_path\" and use_data_from != \"data_dir\"):\n",
    "    raise ValueError(\"use_data_from should be either 'url_path' or 'data_dir'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: display the names of the files in the raw data directory.\n",
    "if use_data_from == \"data_dir\":\n",
    "    print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a data file to plot.\n",
    "file_name = \"log_daily_ip_201806a.txt\"\n",
    "if use_data_from == \"data_dir\":\n",
    "    daily_ip_file = data_dir + file_name\n",
    "elif use_data_from == \"url_path\":\n",
    "    daily_ip_file = url_path + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional:  display the first few lines of the daily_ip_file.\n",
    "lines_to_display = 3\n",
    "if use_data_from == \"data_dir\":\n",
    "    with open(daily_ip_file) as file:\n",
    "        line_num = 1\n",
    "        while line_num <= lines_to_display:\n",
    "            print(file.readline())\n",
    "            line_num = line_num + 1\n",
    "    file.close()\n",
    "elif use_data_from == \"url_pathSKIP\":\n",
    "    # METHOD 1\n",
    "    # Thanks to https://stackoverflow.com/questions/1393324/in-python-given-a-url-to-a-text-file-what-is-the-simplest-way-to-read-the-cont\n",
    "    raw_data = urllib.request.urlopen(daily_ip_file)\n",
    "    line_num = 1\n",
    "    for line in raw_data:\n",
    "        print(line)\n",
    "        line_num = line_num + 1\n",
    "        if line_num > lines_to_display:\n",
    "            break\n",
    "elif use_data_from == \"url_path\":\n",
    "    # METHOD 2\n",
    "    # Thanks to https://stackoverflow.com/questions/1393324/in-python-given-a-url-to-a-text-file-what-is-the-simplest-way-to-read-the-cont\n",
    "    response = requests.get(daily_ip_file)\n",
    "    raw_data = response.text\n",
    "    raw_data_lines = raw_data.split('\\n')\n",
    "    line_num = 1\n",
    "    while line_num <= lines_to_display:\n",
    "        print(raw_data_lines[line_num-1])\n",
    "        line_num = line_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file into a pandas dataframe, df.\n",
    "# The columns separator is '|'.\n",
    "# There is no header row.\n",
    "# We only need the first two columns.\n",
    "df = pd.read_csv(daily_ip_file, sep=\"|\", header=None, usecols=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: display the first few rows.  There should now be only two columns, not five.\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the dataframe's columns descriptive names.\n",
    "df.columns = [\"dates\", \"unique_ips\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: make sure the column names have changed.  Display information about the columns.\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: what is the type of the df.dates column, first row?\n",
    "print(type(df.dates[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the \"object\" data in the df.dates column to date/time objects so they will be treated as such.\n",
    "\n",
    "# Thanks to Burke Squires for this function adapted from\n",
    "# https://github.com/burkesquires/python_biologist/blob/master/05_python_data_analysis\n",
    "\n",
    "# Define a function to convert a string (m/d/yyyy) to a date\n",
    "def string_to_date(date_text):\n",
    "    '''\n",
    "    string_to_date(a_str) converts a_str from format mm/dd/yyyy to a datetime object yyyy-mm-dd.\n",
    "    string_to_date(\"12/25/2018\") converts string 12/25/2018 to datetime object 2018-12-25.\n",
    "    '''\n",
    "    return datetime.strptime(date_text, \"%m/%d/%Y\")\n",
    "\n",
    "# Run the string_to_date function on every date string and overwrite the df.dates column\n",
    "df.dates = df.dates.apply(string_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: what is the type of the df.dates column, first row, now?\n",
    "print(type(df.dates[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Display information about the columns.  Now df.dates is datetime64 instead of object.\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: what does the data in the df.dates column look like now?  yyyy-mm-dd instead of mm/dd/yyyy!\n",
    "print(df.dates.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution:\n",
    "# Don't do this:  df = df.set_index('dates')\n",
    "# Don't set the index to 'dates'.  datetime64 is not iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a quick plot.\n",
    "# The days should display on the x axis (not the df index 0, 1, 2...)\n",
    "# The unique_ips will be used on the y axis.\n",
    "# figsize changes the size to 12 (x) by 3 (y).\n",
    "# title adds the title to the plot.\n",
    "df.plot.bar(x='dates',figsize=(12,3),title=daily_ip_file,legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the median number (half above, half below) of unique IP addresses accessed in a day?\n",
    "print(df.unique_ips.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the lowest number of unique IP addresses in a day?\n",
    "print(df.unique_ips.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What day is associated with the lowest number of unique IP addresses?\n",
    "# The day(s) when df.unique_ips.min() == df.unique_ips\n",
    "print(df.dates[df.unique_ips==df.unique_ips.min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the highest number of unique IP addresses in a day?\n",
    "print(df.unique_ips.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What day is associated with the highest number of IP addresses?\n",
    "# The day(s) when df.unique_ips.max() == df.unique_ips\n",
    "print(df.dates[df.unique_ips==df.unique_ips.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple loop in case you want to keep plotting a smaller date range.\n",
    "answer = \"Y\"\n",
    "while answer == \"Y\":\n",
    "    print(\"Got here 1\")\n",
    "    answer = input(\"Do you want to plot a subset of the data? (Y=Yes) \")\n",
    "    if answer != \"Y\":\n",
    "        break\n",
    "    else:\n",
    "        range_begin = input(\"What is the start of the range? (Default = 06/01/2018) \")\n",
    "        range_begin = range_begin.apply(string_to_date)\n",
    "        print(range_begin)\n",
    "        # range_end = input(\"What is tne end of the range? (Default = 06/30/2018) \")\n",
    "        # df_subset = df[df.dates>=range_begin and df.dates<=range_end]\n",
    "        # print(df_subset)\n",
    "print(\"Got here 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future\n",
    "\n",
    "1. I will incorporate this project into my work immediately.  (Until now, I imported the data into Excel and made a graph.)\n",
    "\n",
    "2. Break my program into functions and restructure my project files\n",
    "\n",
    "3. Scrub IP addresses from raw log files and extract data from them\n",
    "\n",
    "4. List the most accessed URLs on days with high IP address counts\n",
    "\n",
    "5. List the top referrers on days with high IP address counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments and Thanks!\n",
    "\n",
    "BIOF 309 Instructors\n",
    "* Martin Skarzynski\n",
    "* Jinping Liu\n",
    "* Michael Chambers\n",
    "\n",
    "BIOF 309 Class\n",
    "* Helpful questions\n",
    "\n",
    "NIAID Scientific Programming Seminars through CIT\n",
    "* Burke Squires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
